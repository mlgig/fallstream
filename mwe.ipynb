{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9b38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.classifiers import CostClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0bb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_threshold(model, X_train, y_train, X_test, y_test, alpha=2, n_thresholds=100):\n",
    "    \"\"\"Fit model, sweep thresholds, pick tau that maximizes cost-sensitive gain.\"\"\"\n",
    "    model = clone(model).fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    taus = np.linspace(0, 1, n_thresholds)\n",
    "\n",
    "    def gain(y_true, y_pred):\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        return -(fp + alpha * fn)\n",
    "\n",
    "    best_gain, best_tau = -np.inf, 0.5\n",
    "    for tau in taus:\n",
    "        preds = (probs >= tau).astype(int)\n",
    "        g = gain(y_test, preds)\n",
    "        if g > best_gain:\n",
    "            best_gain, best_tau = g, tau\n",
    "    return best_tau, best_gain, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04987725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X, y, dataset_name, alpha=3):\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    base_models = [\n",
    "        make_pipeline(StandardScaler(), LogisticRegression(max_iter=500)),\n",
    "        RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5))\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "\n",
    "    # Evaluate base models\n",
    "    for model in base_models:\n",
    "        name = model.steps[-1][0] if hasattr(model, \"steps\") else model.__class__.__name__\n",
    "        results.extend(evaluate_model(name, model, X_train, y_train, X_test, y_test, alpha=alpha))\n",
    "\n",
    "    # Evaluate ensembles\n",
    "    results.extend(evaluate_costcv(base_models, X_train, y_train, X_test, y_test, alpha=alpha, method=\"dirichlet\"))\n",
    "    results.extend(evaluate_costcv(base_models, X_train, y_train, X_test, y_test, alpha=alpha, method=\"stacking\"))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"\\nSummary Table:\")\n",
    "    display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d853ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, alpha=2, n_thresholds=100):\n",
    "    \"\"\"Evaluate a base model with untuned τ=0.5 and tuned τ maximizing gain.\"\"\"\n",
    "    model = clone(model).fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Untuned (τ=0.5)\n",
    "    preds_untuned = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Tuned (sweep thresholds)\n",
    "    tau_best, best_gain = 0.5, -np.inf\n",
    "    taus = np.linspace(0, 1, n_thresholds)\n",
    "    for tau in taus:\n",
    "        preds = (probs >= tau).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "        g = -(fp + alpha * fn)\n",
    "        if g > best_gain:\n",
    "            best_gain, tau_best, preds_best = g, tau, preds\n",
    "\n",
    "    def metrics(y_true, y_pred):\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "        prec = tp / (tp + fp + 1e-9)\n",
    "        rec = tp / (tp + fn + 1e-9)\n",
    "        f1 = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "        g = -(fp + alpha * fn)\n",
    "        return acc, prec, rec, f1, g\n",
    "\n",
    "    acc_u, prec_u, rec_u, f1_u, g_u = metrics(y_test, preds_untuned)\n",
    "    acc_t, prec_t, rec_t, f1_t, g_t = metrics(y_test, preds_best)\n",
    "\n",
    "    results = [\n",
    "        {\"Model\": name, \"Type\": \"Untuned\", \"Tau\": 0.5, \"Acc\": acc_u, \"Prec\": prec_u, \"Rec\": rec_u, \"F1\": f1_u, \"Gain\": g_u},\n",
    "        {\"Model\": name, \"Type\": \"Tuned\", \"Tau\": tau_best, \"Acc\": acc_t, \"Prec\": prec_t, \"Rec\": rec_t, \"F1\": f1_t, \"Gain\": g_t}\n",
    "    ]\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_costcv(base_models, X_train, y_train, X_test, y_test, alpha=2, method=\"dirichlet\"):\n",
    "    clf = CostClassifierCV(base_models, alpha=alpha, random_state=42, method=method)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec = tp / (tp + fp + 1e-9)\n",
    "    rec = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "    g = -(fp + alpha * fn)\n",
    "\n",
    "    results = [{\n",
    "        \"Model\": f\"Ensemble-{method}\", \"Type\": \"Tuned\", \"Tau\": clf.threshold_,\n",
    "        \"Acc\": acc, \"Prec\": prec, \"Rec\": rec, \"F1\": f1, \"Gain\": g\n",
    "    }]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50eab3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Breast Cancer ===\n",
      "\n",
      "Summary Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Tau</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregression</td>\n",
       "      <td>Untuned</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logisticregression</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Untuned</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.953216</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kneighborsclassifier</td>\n",
       "      <td>Untuned</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968326</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kneighborsclassifier</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968326</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ensemble-dirichlet</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensemble-stacking</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model     Type       Tau       Acc      Prec       Rec  \\\n",
       "0      logisticregression  Untuned  0.500000  0.988304  0.990654  0.990654   \n",
       "1      logisticregression    Tuned  0.363636  0.994152  0.990741  1.000000   \n",
       "2  RandomForestClassifier  Untuned  0.500000  0.941520  0.944954  0.962617   \n",
       "3  RandomForestClassifier    Tuned  0.272727  0.953216  0.938053  0.990654   \n",
       "4    kneighborsclassifier  Untuned  0.500000  0.959064  0.938596  1.000000   \n",
       "5    kneighborsclassifier    Tuned  0.404040  0.959064  0.938596  1.000000   \n",
       "6      Ensemble-dirichlet    Tuned  0.525253  0.994152  0.990741  1.000000   \n",
       "7       Ensemble-stacking    Tuned  0.515152  0.994152  0.990741  1.000000   \n",
       "\n",
       "         F1  Gain  \n",
       "0  0.990654    -4  \n",
       "1  0.995349    -1  \n",
       "2  0.953704   -18  \n",
       "3  0.963636   -10  \n",
       "4  0.968326    -7  \n",
       "5  0.968326    -7  \n",
       "6  0.995349    -1  \n",
       "7  0.995349    -1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Breast Cancer dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "df_bc = run_experiment(X, y, \"Breast Cancer\", alpha=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30fd4f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Synthetic Imbalanced ===\n",
      "\n",
      "Summary Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Tau</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1</th>\n",
       "      <th>Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregression</td>\n",
       "      <td>Untuned</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>-184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logisticregression</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>-122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Untuned</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>-96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kneighborsclassifier</td>\n",
       "      <td>Untuned</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>-182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kneighborsclassifier</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.579235</td>\n",
       "      <td>-113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ensemble-dirichlet</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.662420</td>\n",
       "      <td>-93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensemble-stacking</td>\n",
       "      <td>Tuned</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>-88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model     Type       Tau       Acc      Prec       Rec  \\\n",
       "0      logisticregression  Untuned  0.500000  0.926667  0.750000  0.435484   \n",
       "1      logisticregression    Tuned  0.202020  0.896667  0.500000  0.758065   \n",
       "2  RandomForestClassifier  Untuned  0.500000  0.926667  0.846154  0.354839   \n",
       "3  RandomForestClassifier    Tuned  0.151515  0.866667  0.432836  0.935484   \n",
       "4    kneighborsclassifier  Untuned  0.500000  0.936667  0.928571  0.419355   \n",
       "5    kneighborsclassifier    Tuned  0.010101  0.871667  0.438017  0.854839   \n",
       "6      Ensemble-dirichlet    Tuned  0.141414  0.911667  0.547368  0.838710   \n",
       "7       Ensemble-stacking    Tuned  0.121212  0.893333  0.491228  0.903226   \n",
       "\n",
       "         F1  Gain  \n",
       "0  0.551020  -184  \n",
       "1  0.602564  -122  \n",
       "2  0.500000  -204  \n",
       "3  0.591837   -96  \n",
       "4  0.577778  -182  \n",
       "5  0.579235  -113  \n",
       "6  0.662420   -93  \n",
       "7  0.636364   -88  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Synthetic imbalanced dataset\n",
    "X2, y2 = make_classification(n_samples=2000, n_features=20, n_informative=10,\n",
    "                             n_redundant=5, n_classes=2, weights=[0.9, 0.1],\n",
    "                             flip_y=0.01, random_state=42)\n",
    "df_syn = run_experiment(X2, y2, \"Synthetic Imbalanced\", alpha=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
